{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/monacofj/moeabench/blob/main/examples/example_15.ipynb)\n",
                "\n",
                "# Example 15: The Triple-Mode Hypervolume (Raw, Relative, Absolute)\n",
                "\n",
                "This example demonstrates the three scaling perspectives available for Hypervolume in MoeaBench:\n",
                "1. **'raw'**: Physical volume conquered ($H_{raw}$). Invariant to neighbors or competitors.\n",
                "2. **'relative'**: Competitive efficiency ($H_{rel}$). Scaled by the best observed session front, forcing a 1.0 ceiling for the current winner.\n",
                "3. **'absolute'**: Theoretical optimality ($H_{abs}$). Scaled by the mathematical **Ground Truth** (requires calibration).\n",
                "\n",
                "> **Terminology Note**: In this example, we compare a **Baseline** configuration (20 individuals) against a **Premium** configuration (100 individuals) to show how they behave under different normalization schemes.\n",
                "\n",
                "> **Visual Note**: The mathematical shape of the curves across these three modes is identical because moving between scales merely divides the physical raw volume by a distinct scalar constant. What changes is the vertical scaling and where the curves land relative to a 1.0 ceiling constraint."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install MoeaBench from GitHub (Uncomment if running in Colab)\n",
                "# !pip install --quiet git+https://github.com/monacofj/moeabench.git"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from MoeaBench import mb\n",
                "print(f\"MoeaBench v{mb.system.version()}\")"
            ],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup the Problem and Calibration\n",
                "\n",
                "We use **DTLZ2** (3 objectives). To enable the **Absolute** mode, we must first ensure the problem is calibrated."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "dtlz2 = mb.mops.DTLZ2(n_var=7, n_obj=3)\n",
                "dtlz2.calibrate()\n",
                "\n",
                "print(\"\\nRunning Experiment 1 (Baseline: 20 individuals)...\\n\")\n",
                "exp1 = mb.experiment(dtlz2, mb.moeas.NSGA2(population=20, generations=50))\n",
                "exp1.name = \"Baseline NSGA-II\"\n",
                "exp1.run(repeat=5)\n",
                "\n",
                "print(\"\\nRunning Experiment 2 (Premium: 100 individuals)...\\n\")\n",
                "exp2 = mb.experiment(dtlz2, mb.moeas.NSGA2(population=100, generations=50))\n",
                "exp2.name = \"Premium NSGA-II\"\n",
                "exp2.run(repeat=5)"
            ],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Calculating the Three Perspectives\n",
                "\n",
                "We calculate the hypervolume for both experiments using the three scales."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "global_ref = [exp1, exp2]\n",
                "\n",
                "# A) Raw: Physical volume ($H_{raw}$)\n",
                "hv1_raw = mb.metrics.hv(exp1, ref=global_ref, scale='raw')\n",
                "hv2_raw = mb.metrics.hv(exp2, ref=global_ref, scale='raw')\n",
                "\n",
                "# B) Relative: Competitive Efficiency ($H_{rel}$)\n",
                "hv1_rel = mb.metrics.hv(exp1, ref=global_ref, scale='relative')\n",
                "hv2_rel = mb.metrics.hv(exp2, ref=global_ref, scale='relative')\n",
                "\n",
                "# C) Absolute: Theoretical Optimality ($H_{abs}$)\n",
                "hv1_abs = mb.metrics.hv(exp1, scale='absolute')\n",
                "hv2_abs = mb.metrics.hv(exp2, scale='absolute')\n",
                "\n",
                "print(\"--- RESULTS AT FINAL GENERATION ---\")\n",
                "print(f\"-> Raw:  exp1={hv1_raw.values[-1,:].mean():.4f}, exp2={hv2_raw.values[-1,:].mean():.4f}\")\n",
                "print(f\"-> Rel:  exp1={hv1_rel.values[-1,:].mean():.4f}, exp2={hv2_rel.values[-1,:].mean():.4f}\")\n",
                "print(f\"-> Abs:  exp1={hv1_abs.values[-1,:].mean():.4f}, exp2={hv2_abs.values[-1,:].mean():.4f}\")"
            ],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visual Comparison\n",
                "\n",
                "We plot the three modes side-by-side using unified axes and annotated reference lines."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 5))\n",
                "\n",
                "v1_raw, v2_raw = hv1_raw.values[-1,:].mean(), hv2_raw.values[-1,:].mean()\n",
                "v1_rel, v2_rel = hv1_rel.values[-1,:].mean(), hv2_rel.values[-1,:].mean()\n",
                "v1_abs, v2_abs = hv1_abs.values[-1,:].mean(), hv2_abs.values[-1,:].mean()\n",
                "\n",
                "# Unified Y-axis based on Raw\n",
                "y_max = max(1.05, v2_raw * 1.05)\n",
                "\n",
                "def annotate_lines(ax, val1, val2):\n",
                "    ax.axhline(val1, color='blue', linestyle=':', alpha=0.5)\n",
                "    ax.text(0.5, val1 - y_max*0.01, f\"hv1 = {val1:.3f}\", color='blue', fontsize=8, va='top', ha='left')\n",
                "    ax.axhline(val2, color='darkorange', linestyle=':', alpha=0.5)\n",
                "    ax.text(0.5, val2 - y_max*0.01, f\"hv2 = {val2:.3f}\", color='darkorange', fontsize=8, va='top', ha='left')\n",
                "    ax.set_ylim([0, y_max])\n",
                "\n",
                "# Plotting without manual labels to verify engine standardization\n",
                "mb.view.perf_history(hv1_raw, hv2_raw, ax=ax1, title=\"1. Physical (Raw)\")\n",
                "annotate_lines(ax1, v1_raw, v2_raw)\n",
                "\n",
                "mb.view.perf_history(hv1_rel, hv2_rel, ax=ax2, title=\"2. Competitive (Relative)\")\n",
                "annotate_lines(ax2, v1_rel, v2_rel)\n",
                "ax2.axhline(1.0, color='gray', linestyle='--', alpha=0.7, label=\"Session Winner (1.0)\")\n",
                "ax2.legend(loc='lower right', fontsize=8)\n",
                "\n",
                "mb.view.perf_history(hv1_abs, hv2_abs, ax=ax3, title=\"3. Theoretical (Absolute)\")\n",
                "annotate_lines(ax3, v1_abs, v2_abs)\n",
                "ax3.axhline(1.0, color='gold', linestyle='--', alpha=1.0, label=\"Ground Truth (1.0)\")\n",
                "ax3.legend(loc='lower right', fontsize=8)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "1. **RAW** is an invariant physical scale independent of competitors.\n",
                "2. **RELATIVE** ($H_{rel}$) measures efficiency against the session winner.\n",
                "3. **ABSOLUTE** ($H_{abs}$) measures optimality against the Ground Truth."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}