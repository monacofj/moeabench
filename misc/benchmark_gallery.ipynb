{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/monacofj/moeabench/blob/add-test/misc/benchmark_gallery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MoeaBench: Scientific Audit Confrontation\n",
                "This notebook provides a systematic visual audit comparing the **Legacy2_optimal** against the **Analytical Ground Truth (v0.7.5)**.\n",
                "\n",
                "It demonstrates the jump in mathematical precision and identifies the geometric displacement of legacy truths.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Environment Setup & Root Discovery\n",
                "import os\n",
                "import sys\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "def discover_root():\n",
                "    # Check Colab\n",
                "    if 'google.colab' in str(get_ipython()):\n",
                "        if not os.path.exists('moeabench'):\n",
                "            !git clone -b add-test https://github.com/monacofj/moeabench.git\n",
                "        %cd moeabench\n",
                "        !git pull origin add-test\n",
                "        !pip install -e .\n",
                "        return os.getcwd()\n",
                "    \n",
                "    # Local: search for MoeaBench package anchor\n",
                "    curr = os.getcwd()\n",
                "    for _ in range(3):\n",
                "        if os.path.exists(os.path.join(curr, \"MoeaBench\")):\n",
                "            return curr\n",
                "        curr = os.path.dirname(curr)\n",
                "    return os.getcwd()\n",
                "\n",
                "PROJECT_ROOT = discover_root()\n",
                "if PROJECT_ROOT not in sys.path:\n",
                "    sys.path.append(PROJECT_ROOT)\n",
                "\n",
                "import MoeaBench as mb\n",
                "from MoeaBench.core import SmartArray\n",
                "print(f\"Project Root: {PROJECT_ROOT}\")\n",
                "print(f\"MoeaBench version: {mb.system.version()}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visual Auditor Helper\n",
                "Logic to resolve absolute paths for artifacts and overlay data series (v0.7.5 vs Legacy2_optimal)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def audit_confrontation(mop_name, M=3):\n",
                "    print(f\"--- Analyzing {mop_name} (M={M}) ---\")\n",
                "    \n",
                "    # 1. Setup Problem & Manager\n",
                "    exp = mb.experiment()\n",
                "    try:\n",
                "        mop = getattr(mb.mops, mop_name)(M=M)\n",
                "    except:\n",
                "        # Handle DPF which requires D\n",
                "        mop = getattr(mb.mops, mop_name)(M=M, D=M-1)\n",
                "    exp.mop = mop\n",
                "    \n",
                "    # 2. Load New Truth (v0.7.5)\n",
                "    try:\n",
                "        f_gt_pop = exp.optimal(n_points=1000)\n",
                "        F_gt = f_gt_pop.objectives\n",
                "        print(f\"[OK] Analytical Truth: {len(F_gt)} points sampled.\")\n",
                "    except Exception as e:\n",
                "        # Fallback (e.g. DTLZ8)\n",
                "        gt_file = os.path.join(PROJECT_ROOT, \"tests/ground_truth\", f\"{mop_name}_{M}_optimal.csv\")\n",
                "        if os.path.exists(gt_file):\n",
                "            F_gt = pd.read_csv(gt_file, header=None).values\n",
                "            print(f\"[OK] Loaded Frozen Truth: {len(F_gt)} points from CSV.\")\n",
                "        else:\n",
                "            print(f\"[CRITICAL] Truth data missing for {mop_name}. Failed optimal() and missing {gt_file}.\")\n",
                "            return\n",
                "            \n",
                "    gt_series = SmartArray(F_gt, name=\"v0.7.5 Ground Truth\")\n",
                "    \n",
                "    # 3. Resolve Legacy2_optimal (legacy2_optimal)\n",
                "    legacy2_dir = os.path.join(PROJECT_ROOT, \"tests/legacy2_optimal\")\n",
                "    legacy2_files = [f for f in os.listdir(legacy2_dir) if f.startswith(f\"legacy_{mop_name}_M_{M}\") and f.endswith(\".csv\")]\n",
                "    \n",
                "    overlays = [gt_series]\n",
                "    \n",
                "    if legacy2_files:\n",
                "        leg_v2_path = os.path.join(legacy2_dir, legacy2_files[0])\n",
                "        F_leg2 = pd.read_csv(leg_v2_path, header=None).values\n",
                "        overlays.append(SmartArray(F_leg2, name=\"Legacy2_optimal (v2)\"))\n",
                "        print(f\"[OK] Loaded Legacy2_optimal: {len(F_leg2)} points found at {leg_v2_path}.\")\n",
                "    else:\n",
                "        print(f\"[WARNING] Legacy2_optimal file not found for {mop_name}. Plotting GT only.\")\n",
                "        \n",
                "    # 4. OVERLAY\n",
                "    mb.view.topo_shape(*overlays, title=f\"{mop_name} (M={M}): Confronto v0.7.5 vs Legacy2_optimal\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. DTLZ Family Audits"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ3\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ4\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ5\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ6\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ7\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ8\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DTLZ9\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. DPF Family Audits"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DPF1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DPF2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DPF3\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DPF4\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "audit_confrontation(\"DPF5\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}