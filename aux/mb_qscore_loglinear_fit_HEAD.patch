diff --git a/MoeaBench/diagnostics/qscore.py b/MoeaBench/diagnostics/qscore.py
--- a/MoeaBench/diagnostics/qscore.py
+++ b/MoeaBench/diagnostics/qscore.py
@@ -85,6 +85,31 @@
     # Clip and Invert
     return float(1.0 - np.clip(error_score, 0.0, 1.0))
 
+
+def _compute_q_loglinear(fair_val: float, ideal: float, rand50: float) -> float:
+    """Log-linear variant of the Q-score mapping.
+
+    Keeps the same anchors as the linear mapping (Q=1 at `ideal`, Q=0 at
+    `rand50`), but expands resolution near Q~1 when `fair_val` is small.
+
+        q = 1 - clip( log1p(fair-ideal) / log1p(rand50-ideal) )
+
+    This is useful when the linear mapping compresses most realistic values
+    into Q very close to 1.0.
+    """
+    denom_raw = rand50 - ideal
+    if denom_raw <= 1e-12:
+        return 1.0 if fair_val <= ideal + 1e-12 else 0.0
+
+    # Ensure non-negative arguments to log1p.
+    num_raw = max(fair_val - ideal, 0.0)
+    denom = np.log1p(denom_raw)
+    if denom <= 1e-12:
+        return 1.0 if num_raw <= 1e-12 else 0.0
+
+    error_score = np.log1p(num_raw) / denom
+    return float(1.0 - np.clip(error_score, 0.0, 1.0))
+
 def _compute_q_ecdf(fair_val: float, ideal: float, rand50: float, rand_ecdf: np.ndarray) -> float:
     """
     ECDF Q-Score formula.
@@ -122,10 +147,14 @@
     return float(1.0 - np.clip(error_score, 0.0, 1.0))
 
 def compute_q_fit(fair_fit: float, problem: str, k: int) -> float:
-    """Computes Q_FIT using strict linear baseline (Ideal -> Rand50)."""
+    """Computes Q_FIT using a log-linear baseline (Ideal -> Rand50).
+
+    This keeps the same semantics as the linear mapping (0.0 is ideal, Rand50 is
+    the random anchor), but reduces saturation near Q~1 when FAIR is very small.
+    """
     # Ideal = 0.0 (Perfect physical match)
     _, rand50 = baselines.get_baseline_values(problem, k, "fit")
-    return _compute_q_linear(fair_fit, 0.0, rand50)
+    return _compute_q_loglinear(fair_fit, 0.0, rand50)
 
 def compute_q_coverage(fair_cov: float, problem: str, k: int) -> float:
     """Computes Q_COVERAGE using ECDF."""
@@ -163,31 +192,15 @@
     # 1. Normalize
     fair_vals = dists / s_fit
     
-    # 2. Get Baseline
+    # 2. Get Baseline (Rand50 in FAIR space)
     _, rand50 = baselines.get_baseline_values(problem, k, "fit")
-    
-    # 3. Vectorized ECDF
-    _, rand50, rand_ecdf = baselines.get_baseline_ecdf(problem, k, "fit")
-    N = len(rand_ecdf)
-    
-    # searchsorted is vectorized for the 'v' argument (fair_vals)
-    idx_fair = np.searchsorted(rand_ecdf, fair_vals, side='right')
-    F_fair = idx_fair / N
-    
-    # Scalar lookups for Ideal/Rand
-    idx_ideal = np.searchsorted(rand_ecdf, 0.0, side='right')
-    F_ideal = idx_ideal / N
-    
-    idx_rand = np.searchsorted(rand_ecdf, rand50, side='right')
-    F_rand = idx_rand / N
-    
-    denom = F_rand - F_ideal
-    
+
+    # 3. Vectorized log-linear mapping (same anchors as compute_q_fit)
+    denom_raw = max(rand50, 0.0)
+    denom = np.log1p(denom_raw)
     if denom <= 1e-12:
-         # ideal ~ rand
-         return np.where(F_fair <= F_ideal + 1e-12, 1.0, 0.0)
-         
-    num = F_fair - F_ideal
-    error_score = num / denom
-    
+        return np.where(fair_vals <= 1e-12, 1.0, 0.0)
+
+    num_raw = np.maximum(fair_vals, 0.0)
+    error_score = np.log1p(num_raw) / denom
     return 1.0 - np.clip(error_score, 0.0, 1.0)
