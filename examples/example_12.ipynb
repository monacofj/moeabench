{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/monacofj/moeabench/blob/main/examples/example_12.ipynb)\n\n",
    "# Example 12: Physical Engineering Audit (FAIR Metrics)\n\n",
    "This example focuses on the \"Facts\" layer of the diagnostic suite.\nUnlike Q-Scores (which are calibrated interpretations), FAIR metrics \nprovide raw, physical measurements of the population's health.\n\nWe simulate a \"Premature Convergence\" scenario where the algorithm \nhas reached the Pareto surface but hasn't yet spread out uniformly,\nleaving large gaps and irregular clusters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MoeaBench from GitHub\n",
    "!pip install --quiet git+https://github.com/monacofj/moeabench.git\n"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from MoeaBench import mb\n",
    "print(f\"MoeaBench v{mb.system.version()}\")\n",
    "\n",
    "print(\"Example 12: Exploring the Physical (FAIR) Layer\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "# Setup: We use DTLZ2 (3 objectives) as our benchmark\n",
    "mop = mb.mops.DTLZ2(M=3)\n",
    "gt = mop.pf(n_points=500)\n",
    "\n",
    "# --- SCENARIO: Good Closeness but Incomplete Coverage ---\n",
    "# We run NSGA-II for a limited duration (30 generations).\n",
    "# At this stage, it usually \"touches\" the front but hasn't filled the gaps.\n",
    "print(\"\\n[Scenario] Simulating 'Premature Convergence': On-target but clustered.\")\n",
    "\n",
    "exp = mb.experiment()\n",
    "exp.mop = mop\n",
    "exp.moea = mb.moeas.NSGA2(population=100, generations=30)\n",
    "exp.run()\n",
    "\n",
    "# 1. Visual Evidence\n",
    "print(\"\\nDisplaying Topology Shape...\")\n",
    "mb.view.topo_shape(exp, gt, \n",
    "                   title=\"Physical Pathology: Premature Convergence\",\n",
    "                   labels=[\"Early Population\", \"Optimal Front (GT)\"],\n",
    "                   show=False) # Headless mode safety\n",
    "\n",
    "# 2. Individual FAIR Metrics (Manual Calculation)\n",
    "print(\"\\nStep 1: Calculating Individual Physical Metrics (Closeness & Coverage)...\")\n",
    "\n",
    "# A. Closeness (Physical Proximity Distribution)\n",
    "# This is the raw data used for the \"Validation\" layer.\n",
    "u_dist = mb.diagnostics.closeness(exp, ground_truth=gt)\n",
    "print(\"\\n--- Physical Insight: Closeness (Raw Distribution) ---\")\n",
    "print(f\"- Mean Distance: {np.mean(u_dist):.4f} resolution-units\")\n",
    "print(f\"- Max Distance (95th percentile): {np.percentile(u_dist, 95):.4f}\")\n",
    "\n",
    "# B. Scalar Clinical/Fair Results\n",
    "# We compute the scalar versions of FAIR metrics\n",
    "f_cov = mb.diagnostics.coverage(exp, ground_truth=gt)\n",
    "f_gap = mb.diagnostics.gap(exp, ground_truth=gt)\n",
    "\n",
    "print(\"\\n--- Physical Insight: Coverage & Gaps ---\")\n",
    "print(f\"- Coverage Score: {float(f_cov):.4f} (Avg distance to manifold)\")\n",
    "print(f\"- Max Gap Detected: {float(f_gap):.4f} (Largest hole size)\")\n",
    "\n",
    "# 3. Consolidated FAIR Audit\n",
    "print(\"\\nStep 2: Performing a Full Physical Engineering Audit...\")\n",
    "# This aggregates all FAIR metrics (Closeness, Coverage, Gap, Regularity, Balance)\n",
    "mb.diagnostics.fair_audit(exp, ground_truth=gt).report_show()\n",
    "\n",
    "# 4. Full Diagnostic Biopsy (Executive Narrative)\n",
    "print(\"\\nStep 3: Performing Full Diagnostic Biopsy...\")\n",
    "diag_res = mb.diagnostics.audit(exp, ground_truth=gt)\n",
    "print(\"\\n--- Executive Summary ---\")\n",
    "print(diag_res.summary())\n",
    "\n",
    "print(\"\\nExample 12 completed.\")\n",
    "\n"
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}