diff --git a/MoeaBench/diagnostics/qscore.py b/MoeaBench/diagnostics/qscore.py
index 7b041c4..988db6a 100644
--- a/MoeaBench/diagnostics/qscore.py
+++ b/MoeaBench/diagnostics/qscore.py
@@ -6,7 +6,7 @@
 MoeaBench Clinical Quality Scores (Engineering Layer)
 =====================================================
 
-This module implements the "Q-Score" logic ($Q \in [0, 1]$).
+This module implements the "Q-Score" logic ($Q \\in [0, 1]$).
 Logic:
 1.  High-is-Better (1.0 = Optimal, 0.0 = Random/Fail).
 2.  Formula: Linear interpolation between Ideal (Q=1) and Random (Q=0).
@@ -18,6 +18,53 @@ Logic:
 import numpy as np
 from . import baselines
 
+
+def _wasserstein_1d(u: np.ndarray, v: np.ndarray) -> float:
+    """Wasserstein-1 distance in 1D (a.k.a. EMD in 1D) without SciPy.
+
+    Both inputs are treated as empirical samples with uniform weights.
+    """
+    u = np.asarray(u, dtype=float)
+    v = np.asarray(v, dtype=float)
+    if u.size == 0 or v.size == 0:
+        return float('nan')
+
+    u = np.sort(u)
+    v = np.sort(v)
+
+    # Merge all sample points; integrate absolute CDF difference.
+    all_x = np.concatenate([u, v])
+    all_x.sort()
+    if all_x.size <= 1:
+        return 0.0
+
+    # Empirical CDF values at left of each interval
+    iu = np.searchsorted(u, all_x[:-1], side='right') / u.size
+    iv = np.searchsorted(v, all_x[:-1], side='right') / v.size
+    dx = np.diff(all_x)
+    return float(np.sum(np.abs(iu - iv) * dx))
+
+
+def compute_q_wasserstein(front_samples: np.ndarray, ideal_samples: np.ndarray, rand_samples: np.ndarray, *, eps: float = 1e-12) -> float:
+    """Distributional Q-score via Wasserstein-1 (EMD 1D).
+
+    Definition:
+        Q = d(F, R) / (d(F, R) + d(F, I))
+
+    where d is Wasserstein-1 on the same scalar FAIR metric.
+    """
+    f = np.asarray(front_samples, dtype=float)
+    i = np.asarray(ideal_samples, dtype=float)
+    r = np.asarray(rand_samples, dtype=float)
+    if f.size == 0 or i.size == 0 or r.size == 0:
+        return float('nan')
+    d_i = _wasserstein_1d(f, i)
+    d_r = _wasserstein_1d(f, r)
+    denom = d_i + d_r
+    if denom <= eps:
+        return 1.0
+    return float(d_r / denom)
+
 def _compute_q_linear(fair_val: float, ideal: float, rand50: float) -> float:
     """
     Linear Q-Score formula.
diff --git a/tests/calibration/audit_calibration.py b/tests/calibration/audit_calibration.py
index 6730a55..db651b8 100644
--- a/tests/calibration/audit_calibration.py
+++ b/tests/calibration/audit_calibration.py
@@ -24,7 +24,7 @@ import glob
 import json
 import numpy as np
 import pandas as pd
-from collections import Counter
+from collections import Counter, defaultdict
 
 # Ensure local MoeaBench is importable
 PROJ_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
@@ -60,18 +60,17 @@ def _aggregate_clinical(mop_name, alg, F_opt):
     pattern = os.path.join(DATA_DIR, f"{mop_name}_{alg}_standard_run[0-9][0-9].csv")
     run_files = sorted(glob.glob(pattern))
     
-    # Q-Score Accumulators
-    fit_vals, cov_vals, gap_vals, reg_vals, bal_vals = [], [], [], [], []
-    
     # Fair Metric Accumulators (Physics)
     fair_fit_vals, fair_cov_vals, fair_gap_vals, fair_reg_vals, fair_bal_vals = [], [], [], [], []
-    
-    # Baseline Accumulators
-    ideal_fit_vals, rand_fit_vals = [], []
-    ideal_cov_vals, rand_cov_vals = [], []
-    ideal_gap_vals, rand_gap_vals = [], []
-    ideal_reg_vals, rand_reg_vals = [], []
-    ideal_bal_vals, rand_bal_vals = [], []
+
+    # Bucket FAIR samples by snapped K to compute distributional Q (Wasserstein)
+    fair_by_k = {
+        'fit': defaultdict(list),
+        'cov': defaultdict(list),
+        'gap': defaultdict(list),
+        'reg': defaultdict(list),
+        'bal': defaultdict(list),
+    }
     
     # Metadata/Extra
     k_used_vals, k_raw_vals = [], []
@@ -127,21 +126,13 @@ def _aggregate_clinical(mop_name, alg, F_opt):
             fair_g = fair.compute_fair_gap(P_eval, F_opt)
             fair_r = fair.compute_fair_regularity(P_eval, U_ref)
             fair_b = fair.compute_fair_balance(P_eval, C_cents, hist_ref)
-
-            q_f = qscore.compute_q_fit(fair_f, mop_name, K_target)
-            q_c = qscore.compute_q_coverage(fair_c, mop_name, K_target)
-            q_g = qscore.compute_q_gap(fair_g, mop_name, K_target)
-            q_r = qscore.compute_q_regularity(fair_r, mop_name, K_target)
-            q_b = qscore.compute_q_balance(fair_b, mop_name, K_target)
-            
-            # Store
-            fit_vals.append(q_f); cov_vals.append(q_c); gap_vals.append(q_g); reg_vals.append(q_r); bal_vals.append(q_b)
+            # Store FAIR values (per-run) and also bucket by K for distributional Q
             fair_fit_vals.append(fair_f); fair_cov_vals.append(fair_c); fair_gap_vals.append(fair_g); fair_reg_vals.append(fair_r); fair_bal_vals.append(fair_b)
-            ideal_fit_vals.append(0.0); rand_fit_vals.append(f_r)
-            ideal_cov_vals.append(c_u); rand_cov_vals.append(c_r)
-            ideal_gap_vals.append(g_u); rand_gap_vals.append(g_r)
-            ideal_reg_vals.append(u_u); rand_reg_vals.append(u_r)
-            ideal_bal_vals.append(b_u); rand_bal_vals.append(b_r)
+            fair_by_k["fit"][K_target].append(fair_f)
+            fair_by_k["cov"][K_target].append(fair_c)
+            fair_by_k["gap"][K_target].append(fair_g)
+            fair_by_k["reg"][K_target].append(fair_r)
+            fair_by_k["bal"][K_target].append(fair_b)
             k_used_vals.append(K_target); k_raw_vals.append(K_raw)
             igd_p_vals.append(GEN_igdplus([F_run], F_opt).evaluate()[0])
             gd_p_vals.append(GEN_gdplus([F_run], F_opt).evaluate()[0])
@@ -152,15 +143,65 @@ def _aggregate_clinical(mop_name, alg, F_opt):
         except Exception: 
             import traceback; traceback.print_exc()
             continue
-
-    n_runs = len(fit_vals)
+    n_runs = len(fair_fit_vals)
     def _med(lst): return float(np.nanmedian(lst)) if len(lst) else np.nan
     def _avg(lst): return float(np.mean(lst)) if len(lst) else np.nan
-        
-    mq = {"fit": _med(fit_vals), "cov": _med(cov_vals), "gap": _med(gap_vals), "reg": _med(reg_vals), "bal": _med(bal_vals)}
+    # Distributional Q via Wasserstein-1 against baseline random ECDF and a practical-ideal sample
+    def _get_practical_ideal_samples(k: int):
+        s_k = base.get_resolution_factor_k(F_opt, k, seed=0)
+        U_ref = base.get_ref_uk(F_opt, k, seed=0)
+        C_cents, _ = base.get_ref_clusters(F_opt, c=32, seed=0)
+        d_u = base.cdist(U_ref, C_cents)
+        lab_u = np.argmin(d_u, axis=1)
+        hist_ref = np.bincount(lab_u, minlength=len(C_cents)).astype(float)
+        hist_ref /= np.sum(hist_ref)
+
+        N_IDEAL = 30
+        vals = {'fit': [], 'cov': [], 'gap': [], 'reg': [], 'bal': []}
+        for i in range(N_IDEAL):
+            pop_uni = base.get_ref_uk(F_opt, k, seed=100+i)
+            vals['fit'].append(fair.compute_fair_fit(pop_uni, F_opt, s_fit=s_k))
+            vals['cov'].append(fair.compute_fair_coverage(pop_uni, F_opt))
+            vals['gap'].append(fair.compute_fair_gap(pop_uni, F_opt))
+            vals['reg'].append(fair.compute_fair_regularity(pop_uni, U_ref))
+            vals['bal'].append(fair.compute_fair_balance(pop_uni, C_cents, hist_ref))
+        return s_k, {m: np.asarray(v, float) for m, v in vals.items()}
+
+    def _q_weighted(metric: str) -> float:
+        total = 0
+        acc = 0.0
+        for k, samples in fair_by_k[metric].items():
+            if len(samples) == 0:
+                continue
+            try:
+                _, _, rand_ecdf = base.get_baseline_ecdf(mop_name, k, metric)
+            except base.UndefinedBaselineError:
+                continue
+            s_k, ideal_samps = _get_practical_ideal_samples(k)
+            q_k = qscore.compute_q_wasserstein(np.asarray(samples, float), ideal_samps[metric], np.asarray(rand_ecdf, float))
+            w = len(samples)
+            total += w
+            acc += float(q_k) * w
+        return acc / total if total > 0 else float('nan')
+
+    mq = {
+        'fit': _q_weighted('fit'),
+        'cov': _q_weighted('cov'),
+        'gap': _q_weighted('gap'),
+        'reg': _q_weighted('reg'),
+        'bal': _q_weighted('bal'),
+    }
     mf = {"fit": _med(fair_fit_vals), "cov": _med(fair_cov_vals), "gap": _med(fair_gap_vals), "reg": _med(fair_reg_vals), "bal": _med(fair_bal_vals)}
-    mi = {"fit": _med(ideal_fit_vals), "cov": _med(ideal_cov_vals), "gap": _med(ideal_gap_vals), "reg": _med(ideal_reg_vals), "bal": _med(ideal_bal_vals)}
-    mr = {"fit": _med(rand_fit_vals), "cov": _med(rand_cov_vals), "gap": _med(rand_gap_vals), "reg": _med(rand_reg_vals), "bal": _med(rand_bal_vals)}
+    # Anchors shown in report: (good) median of practical-ideal sample, (bad) baseline rand50, at reference K
+    k_ref = int(np.nanmedian(k_used_vals)) if len(k_used_vals) else 10
+    s_k_ref, ideal_ref = _get_practical_ideal_samples(k_ref)
+
+    def _rand50(metric: str) -> float:
+        _, r50 = base.get_baseline_values(mop_name, k_ref, metric)
+        return float(r50)
+
+    mi = {m: float(np.nanmedian(ideal_ref[m])) for m in ['fit','cov','gap','reg','bal']}
+    mr = {m: _rand50(m) for m in ['fit','cov','gap','reg','bal']}
     
     summary_list = []
     # Fail-Closed NaN Check
@@ -191,7 +232,7 @@ def _aggregate_clinical(mop_name, alg, F_opt):
         "k_used": _med(k_used_vals), "k_raw": _med(k_raw_vals),
         "igd_p": {"mean": _avg(igd_p_vals), "std": float(np.std(igd_p_vals)) if igd_p_vals else 0},
         "gd_p": {"mean": _avg(gd_p_vals), "std": float(np.std(gd_p_vals)) if gd_p_vals else 0},
-        "s_fit": s_fit if 's_fit' in locals() else 1.0 # The macroscopic ruler (s_K)
+        "s_fit": float(s_k_ref) # The macroscopic ruler (s_K)
     }
 
 def _audit_problem_alg(mop_name, alg, F_opt, mop_df):
