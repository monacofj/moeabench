<!--
SPDX-FileCopyrightText: 2026 Monaco F. J. <monaco@usp.br>
SPDX-FileCopyrightText: 2026 Silva F. F. <fernandoferreira.silva42@usp.br>

SPDX-License-Identifier: GPL-3.0-or-later
-->

# ADR 0036: Half-Normal Projection and KDTree Physics Optimization (v0.12.0)

**Status:** Accepted
**Date:** 2026-02-25
**Author:** Monaco F. J., Silva F. F.
**Drivers:** Scientific Rigor, Geometric Integrity, Performance Scalability.

---

## 1. Abstract

This Architectural Decision Record documents the metrological upgrade implemented in MoeaBench `v0.12.0`. Specifically, this decision:
1. **Replaces the Spherical Noise model with a Half-Normal Projection** for establishing the random baseline in `q_closeness`.
2. **Replaces the exhaustive `cdist` (Distance Matrix) calculation with `scipy.spatial.KDTree`** in the core physical metrics module (`fair.py`).
3. **Introduces Dynamic Baseline Versioning** (`baselines_v0.12.0.json`) to isolate these strict geometric evaluations from legacy approximations.

This decision enforces strict manifold geometry boundaries, preventing baseline artifacts where points could be modeled *inside* the optimal manifold, while ensuring performance scalability for massive data sets.

---

## 2. Problem Statement

### 2.1 The "Phantom Intrusion" Paradox (Spherical Blur)
In previous versions (up to v0.11), the clinical metric `q_closeness` evaluated performance against a "Blind Sampling Baseline". This baseline was generated by taking the Ground Truth (GT) and applying a **Spherical Gaussian Blur** (adding normal noise in all dimensions). 

While mathematically convenient, generating a random atmosphere around the GT creates a paradox: on many benchmark geometries (especially curved or boundary-constrained manifolds), spherical noise pushes points *inside* or *past* the true Pareto optimal barrier. 
Metaphorically, if the true Pareto front is an unbreakable wall, spherical noise assumes algorithms can accidentally guess points *behind* the wall. This breaks the fundamental assumption of multi-objective optimization (that the front is the absolute mathematical limit) and degrades the baseline ECDF, producing artificially inflated Q-Scores.

### 2.2 Exhaustive Computation Bottleneck
The raw physical distance calculation for closeness required finding the nearest GT point for every population point. Previously, this relied on `scipy.spatial.distance.cdist` to compute the full $N \times M$ dense distance matrix. For large high-density benchmarks (e.g., DPF with 10,000 points) or large populations, calculating and storing millions of euclidean relations became computationally prohibitive (memory and CPU saturation).

---

## 3. The Refined Framework (v0.12.0)

### 3.1 Half-Normal Error Projection
We abolished the Spherical Blur in favor of the **Half-Normal Projection**.

*   **Logic:** Rather than blurring the coordinates of the GT and recalculating distances, we directly model the *distribution of error distances*. Since distance is fundamentally a non-negative scalar denoting how far a point is "pushed away" from the optimal surface, its theoretical noise limit is best modeled by the absolute value of a normal distribution.
*   **Formula:** The random baseline distribution $R_d$ is established as:
    $$ R_d = | \mathcal{N}(0, \sigma^2) | $$
    where $\sigma = \sqrt{M_{obj}} / \sqrt{12}$ represents the standard deviation of a uniform random distribution mapped onto the domain, scaled by our resolution unit $s_K$.
*   **Scientific Value:** This guarantees that the baseline noise strictly extends *outward* from the theoretical manifold. Metaphorically, noise bounces off the wall rather than penetrating it. This provides a rigorous and physically realistic baseline ECDF.

### 3.2 KDTree Geometric Optimization
The physical layer (`fair.closeness`) now utilizes `scipy.spatial.KDTree`.

*   **Logic:** Instead of an exhaustive dense matrix, we build a spatial index (KDTree) of the Ground Truth. Searching for the nearest neighbor of each population point shrinks from an $O(N \cdot M)$ brute-force check to a logarithmic $O(N \log M)$ tree traversal.
*   **Performance:** This drops the computational complexity and memory footprint by orders of magnitude, allowing the diagnostic framework to instantly evaluate high-density analytical sets without slowing the researcher workflow down.

### 3.3 Dynamic Versioning
To ensure consistency, the framework now ships with `baselines_v0.12.0.json`. The codebase reads the `version()` dynamically to choose the correct reference set, guaranteeing that older audits do not mix with Half-Normal approximations.

---

## 4. Conclusion
MoeaBench's diagnostic suite is meant to rival the accuracy of a micrometer. Transitioning to the Half-Normal Projection guarantees strict topological adherence to the fundamental Pareto boundary constraint, removing systemic sampling errors. Simultaneously, KDTree integration allows this micrometer to scale effortlessly to massive topologies.
