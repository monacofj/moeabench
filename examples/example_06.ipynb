{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/monacofj/moeabench/blob/main/examples/example_06.ipynb)\n",
    "\n",
    "# Example 06: Statistical Hypothesis Testing\n",
    "\n",
    "This example demonstrates how to perform rigorous statistical comparisons between two algorithms using non-parametric tests and effect size measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet git+https://github.com/monacofj/moeabench.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MoeaBench import mb\n",
    "print(f\"Version: {mb.system.version()}\")\n",
    "\n",
    "# 1. Setup: Compare NSGA-III and SPEA2 with 10 repetitions\n",
    "repeats = 10\n",
    "pop_size = 100\n",
    "gens = 50\n",
    "    \n",
    "exp1 = mb.experiment()\n",
    "exp1.name = \"NSGA-III\"\n",
    "exp1.mop = mb.mops.DTLZ2(M=3)\n",
    "exp1.moea = mb.moeas.NSGA3(population=pop_size, generations=gens)\n",
    "\n",
    "exp2 = mb.experiment()\n",
    "exp2.name = \"SPEA2\"\n",
    "exp2.mop = mb.mops.DTLZ2(M=3)\n",
    "exp2.moea = mb.moeas.SPEA2(population=pop_size, generations=gens)\n",
    "\n",
    "print(f\"Running {repeats} repetitions for each algorithm...\")\n",
    "exp1.run(repeat=repeats)\n",
    "exp2.run(repeat=repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Statistical Inference\n",
    "print(\"\\n--- Inferential Statistics ---\")\n",
    "    \n",
    "# res1 contains:\n",
    "#             .statistic       test statistic (U)\n",
    "#             .p_value         probability of observing the data by chance\n",
    "#             .significant     boolean (p < 0.05)\n",
    "#             .report()        narrative summary\n",
    "res1 = mb.stats.mann_whitney(exp1, exp2)\n",
    "print(res1.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res2 contains:\n",
    "#             .statistic       KS distance (D)\n",
    "#             .p_value         probability of distribution similarity\n",
    "#             .report()        narrative summary\n",
    "res2 = mb.stats.ks_test(exp1, exp2)\n",
    "print(\"\\n\" + res2.report())\n",
    "        \n",
    "# res3 contains:\n",
    "#             .value           Vargha-Delaney A12 effect size [0, 1]\n",
    "#             .report()        narrative summary\n",
    "res3 = mb.stats.a12(exp1, exp2)\n",
    "print(\"\\n\" + res3.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Statistical tests avoid the trap of \"visual optimization.\" The Mann-Whitney U test tells us if one algorithm is significantly better than the other based on the median performance.\n",
    "\n",
    "In MoeaBench, these tests are \"smart\": they automatically handle the extraction of metrics (like Hypervolume) and set a common reference point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}